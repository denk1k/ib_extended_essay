# Research question
### To what extent do the architectural differences between a tree-based ensemble model and a decomposable additive model determine their ability to leverage market sentiment and social engagement features for cryptocurrency price forecasting?

# How to reproduce the experiment
## Prerequisites
Python 3 is required to run the workflow and CoinMarketCap API key is required to use `fetch_coins_and_filter.py` in case you want to rebuild the dataset.
## You can do it automatically via `runner.py`, which will guide you through all the steps
```shell
python3 runner.py
```
## OR, you can do it manually:
> Skip to Step 5 if you wish to run the experiment with data from feature_data, the exact frozen dataset used in the essay (or your own dataset if you already downloaded it).
1. Create the environment, install the necessary dependencies and activate it:
```shell
python3 -m venv .venv && source ./.venv/bin/activate && pip3 install -r requirements.txt
```
2. Run `fetch_coins_and_filter.py` to retrieve the coins that are available in CryptoCompare for all of the streams and are in top 500 by market capitalization according to CoinMarketCap. It asks for a CoinMarketCap API key. This script saves the retrieved information in `data_availability.json`. The execution time is ~10 seconds.
   (This is the first filtering step since data availability on CryptoCompare is the greatest bottleneck)
```shell
python3 fetch_coins_and_filter.py
```
3. Run `market_data.py`, `price_data.py` and `social_data.py`. It is possible to run them simultaneously and start in any order wished as these do not rely on completion of each other. Each of the scripts downloads data to its respective directories (`market_data`, `price_data`, and `social_data`) and generates a JSON report in `data_fetching_stats` directory. The execution time, if run simultaneously, is ~30 minutes.
```shell
python3 market_data.py
python3 social_data.py
python3 price_data.py
```
4. Run `create_features.py`. This script uses functionality from `find_start_date.py`, which requires the reports generated by the data fetching scripts. It saves the feature datasets to `feature_data` directory. The execution time is ~5 seconds.
```shell
python3 create_features.py
```
5. Run `experiment.py`. This is the main experimental workflow, which uses data from `feature_data`. The results are shown in the terminal and saved to the `csv_results` directory. This script first asks whether to run the experiment on limited or all horizons. The execution time is ~2 hours.
```shell
python3 experiment.py
```
6. For buy-and-hold comparison, run `experiment_buy_hold.py`. The results are shown in the terminal. The execution time is ~3 seconds.
```shell
python3 experiment_buy_hold.py
```

